# KDT 2ì°¨ í”„ë¡œì íŠ¸ íŒ€ê³¼ì œ
## ë”¥ëŸ¬ë‹- ì´ë¯¸ì§€ ë¶„ë¥˜

<br>

ğŸ‘€**ì£¼ì œWeather Image Recognition**<br>
https://www.kaggle.com/datasets/jehanbhathena/weather-dataset

---

- í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¼€ê¸€ì—ì„œ AIP í˜•ì‹ìœ¼ë¡œ ë°›ì•„ì˜¨ í›„ ì´ë¯¸ì§€ train, validationìœ¼ë¡œ ë¶„ë¥˜ ì‘ì—… ì§„í–‰
``` python
import os
os.environ['KAGGLE_USERNAME'] = '**'
os.environ['KAGGLE_KEY'] = '**'

!kaggle datasets download -d jehanbhathena/weather-dataset
!unzip -q weather-dataset.zip
```
``` python
import random
import shutil

def split_dataset_by_class(dataset_path, train_path, validation_path, validation_ratio=0.2):
    # í´ë˜ìŠ¤ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    classes = os.listdir(dataset_path)

    for class_name in classes:
        class_path = os.path.join(dataset_path, class_name)
        train_class_path = os.path.join(train_path, class_name)
        validation_class_path = os.path.join(validation_path, class_name)

        # í´ë” ìƒì„±
        if not os.path.exists(train_class_path):
            os.makedirs(train_class_path)
        if not os.path.exists(validation_class_path):
            os.makedirs(validation_class_path)

        # í´ë˜ìŠ¤ í´ë” ë‚´ì˜ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        file_list = os.listdir(class_path)

        # í´ë˜ìŠ¤ ë³„ ë°ì´í„°ì…‹ ì„ê¸°
        random.shuffle(file_list)

        # í´ë˜ìŠ¤ ë³„ ë°ì´í„°ì…‹ì„ trainê³¼ validationìœ¼ë¡œ ë‚˜ëˆ„ê¸°
        num_validation = int(len(file_list) * validation_ratio)
        validation_files = file_list[:num_validation]
        train_files = file_list[num_validation:]

        # validation í´ë”ë¡œ íŒŒì¼ ì´ë™
        for file in validation_files:
            src_path = os.path.join(class_path, file)
            dest_path = os.path.join(validation_class_path, file)
            shutil.move(src_path, dest_path)

        # train í´ë”ë¡œ íŒŒì¼ ì´ë™
        for file in train_files:
            src_path = os.path.join(class_path, file)
            dest_path = os.path.join(train_class_path, file)
            shutil.move(src_path, dest_path)

# ì‚¬ìš© ì˜ˆì‹œ
dataset_path = 'dataset'
train_path = 'train'
validation_path = 'validation'

split_dataset_by_class(dataset_path, train_path, validation_path, validation_ratio=0.2)
```
ìœ„ ì½”ë“œëŒ€ë¡œ ì‘ì„± ì‹œ ì•„ë˜ ì´ë¯¸ì§€ì²˜ëŸ¼ datasetì´ train, validationìœ¼ë¡œ í´ë”ê°€ ë¶„ë¥˜ë˜ê³  ì´ë¯¸ì§€ê°€ ì˜®ê²¨ì§
![image](https://github.com/dev-aram/KDT_TASK/assets/135501045/1215f935-8b6a-47e3-ab11-cded6fa9e10e)

---

### í•„ìš”í•œ ë„êµ¬ ì„í¬íŠ¸
í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ import

``` python
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader, random_split
```

### GPU í™•ì¸
```python
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)
```

### ë°ì´í„° ë³€í˜•
ë°ì´í„° í•™ìŠµ ì‹œ ì˜¤ë²„í”¼íŒ…ì„ ë§‰ê¸° ìœ„í•´ ì¼ë¶€ ë°ì´í„° ë³€í˜• ì‘ì—… ì§„í–‰
```python
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor()
    ]),
    'validation': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
}

def target_transforms(target):
    return torch.FloatTensor([target])
```

### ImageFolaer í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°
> ë¼ë²¨ì„ float íƒ€ì„ìœ¼ë¡œ ë°”ê¿”ì¤„ í•„ìš”ê°€ ì—†ê¸°ë•Œë¬¸ì— target_transformì€ ì œì™¸

```python
image_datasets = {
    'train': datasets.ImageFolder('train', data_transforms['train']),
    'validation': datasets.ImageFolder('validation', data_transforms['validation'])
}
```

### ë°ì´í„° ë¡œë” ìƒì„±
```python
dataloaders = {
    'train': DataLoader(
        image_datasets['train'],
        batch_size=32,
        shuffle=True
    ),
    'validation': DataLoader(
        image_datasets['validation'],
        batch_size=32,
        shuffle=False
    )
}
```

### ì´ë¯¸ì§€ subplotsìœ¼ë¡œ ì‹œê°í™”
```python
imgs, labels = next(iter(dataloaders['train']))
fig, axes = plt.subplots(4, 8, figsize=(16, 8))

for ax, img, label in zip(axes.flatten(), imgs, labels):
    ax.imshow(img.permute(1, 2, 0))
    ax.set_title(label.item())
    ax.axis('off')
```
![image](https://github.com/dev-aram/KDT_TASK/assets/135501045/26c0dbca-c853-4c9e-bf00-ec37e8568d97)

---
### í•™ìŠµ
#### ëª¨ë¸ ì„ ì •(MobileNet V2)
MobileNet V2
Googleì€ 2018ë…„ MobileNet V2ë¥¼ ì œì•ˆí•œ ë…¼ë¬¸ì¸ MobileNetV2: Inverted Residuals and Linear Bottlenecksë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.

MobileNet V2ëŠ” ì´ì „ ëª¨ë¸ì¸ MobileNetì„ ê°œì„ í•œ ë„¤íŠ¸ì›Œí¬ ì…ë‹ˆë‹¤. ë”°ë¼ì„œ MobileNetê³¼ ë™ì¼í•˜ê²Œ MobileNet V2ëŠ” ì„ë² ë””ë“œ ë””ë°”ì´ìŠ¤ ë˜ëŠ” ëª¨ë°”ì¼ ì¥ì¹˜ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ í•˜ëŠ” ë‹¨ìˆœí•œ êµ¬ì¡°ì˜ ê²½ëŸ‰í™” ë„¤íŠ¸ì›Œí¬ë¥¼ ì„¤ê³„í•˜ëŠ”ë° ì´ˆì ì´ ë§ì¶°ì ¸ ìˆìŠµë‹ˆë‹¤.

MobileNet V2ëŠ” MobileNet V1ì„ ê¸°ë°˜ìœ¼ë¡œ ë‘ê³  ëª‡ê°€ì§€ ê°œì„ ì ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. MobileNet V1ì—ì„œ ì‚¬ìš©í•˜ë˜ Depthwise-Separable Convolutionì„ ì£¼ë¡œ ì‚¬ìš©í•˜ê³  width/resolution multiplyerë¥¼ ì‚¬ìš©í•´ ì •í™•ë„ì™€ ëª¨ë¸ í¬ê¸°ë¥¼ trade-offí•˜ëŠ” ë“± ìœ ì‚¬í•œ ì ì´ ë§ìŠµë‹ˆë‹¤.

í•˜ì§€ë§Œ ë‹¨ìˆœíˆ Depthwise-Separable Convolutionì„ ìŒ“ì€ êµ¬ì¡°ì˜ MobileNetê³¼ëŠ” ë‹¬ë¦¬ MobileNet v2ì—ì„œëŠ” Inverted Residual blockì´ë¼ëŠ” êµ¬ì¡°ë¥¼ ì´ìš©í•´ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì„±í•œ ì°¨ì´ì ì´ ìˆìŠµë‹ˆë‹¤.

âœ¨ ì°¸ì¡° https://velog.io/@woojinn8/LightWeight-Deep-Learning-7.-MobileNet-v2

---

#### ì‚¬ìš©ë°©ë²•
```python
model = models.mobilenet_v2(pretrained=True).to(device)
model
```
**ë³€ê²½ ì „ classifier**
![image](https://github.com/dev-aram/KDT_TASK/assets/135501045/8b73cbcc-3b16-40d1-af93-9a4397304f84)

**ë‚´ ë°ì´í„°ì— ë§ê²Œ ëª¨ë¸ ë³€ê²½**
```python
for param in model.parameters():
    param.requires_grad = False

model.classifier = nn.Sequential(
    nn.Linear(1280, 512),
    nn.ReLU(),
    nn.Linear(512, 128),
    nn.Sigmoid(),
    nn.Linear(128, 11)
).to(device)

print(model)
```
**ë³€ê²½ í›„ classifier**
![image](https://github.com/dev-aram/KDT_TASK/assets/135501045/ebcc3d6e-a705-4486-8d88-7e31d059e3c6)

---

#### í•™ìŠµ ì§„í–‰
```python
# í•™ìŠµ
optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)

epochs = 10

for epoch in  range(epochs + 1):
    for phase in ['train', 'validation']:
        if phase == 'train':
            model.train()
        else:
            model.eval()
        sum_losses = 0
        sum_accs = 0

        for x_batch, y_batch in dataloaders[phase]:
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)

            y_pred = model(x_batch)
            loss = nn.CrossEntropyLoss()(y_pred, y_batch)
            if phase == 'train':
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

            sum_losses = sum_losses + loss
            y_prob = nn.Softmax(1)(y_pred)
            y_pred_index = torch.argmax(y_prob, axis=1)

            acc = (y_batch == y_pred_index).float().sum() / len(y_batch) * 100
            sum_accs = sum_accs + acc

        avg_loss = sum_losses / len(dataloaders[phase])
        avg_acc = sum_accs / len(dataloaders[phase])
        print(f'{phase:10s}: Epoch {epoch+1:4d}/{epochs} Loss: {avg_loss:.4f} Accuracy: {avg_acc: .2f}%')

```

> train     : Epoch   11/10 Loss: 0.3118 Accuracy:  89.14%
> validation: Epoch   11/10 Loss: 0.3706 Accuracy:  87.09%

í•™ìŠµë¥ ì´ ë‚®ê²Œë‚˜ì™€ ëª¨ë¸ ì €ì¥ í›„ ë‹¤ì‹œ í•™ìŠµ ì§„í–‰

#### ëª¨ë¸ ì €ì¥
```python
torch.save(model.state_dict(),'model.pth') # model.h5 (í…ì„œí”Œë¡œìš°)
```

---

```python
for epoch in  range(epochs + 1):
    for phase in ['train', 'validation']:
        if phase == 'train':
            model.train()
        else:
            model.eval()
        sum_losses = 0
        sum_accs = 0

        for x_batch, y_batch in dataloaders[phase]:
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)

            y_pred = model(x_batch)
            loss = nn.CrossEntropyLoss()(y_pred, y_batch)
            if phase == 'train':
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

            sum_losses = sum_losses + loss
            y_prob = nn.Softmax(1)(y_pred)
            y_pred_index = torch.argmax(y_prob, axis=1)

            acc = (y_batch == y_pred_index).float().sum() / len(y_batch) * 100
            sum_accs = sum_accs + acc

        avg_loss = sum_losses / len(dataloaders[phase])
        avg_acc = sum_accs / len(dataloaders[phase])
        print(f'{phase:10s}: Epoch {epoch+1:4d}/{epochs} Loss: {avg_loss:.4f} Accuracy: {avg_acc: .2f}%')

```
> train     : Epoch   11/10 Loss: 0.1785 Accuracy:  93.69%
> validation: Epoch   11/10 Loss: 0.4038 Accuracy:  87.67%
> í•™ìŠµë¥ ê³¼ ì •í™•ë„ê°€ ìƒìŠ¹

---

## í…ŒìŠ¤íŠ¸
ë§Œë“  ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ì§„í–‰

```python
# í…ŒìŠ¤íŠ¸
from PIL import Image
img1 = Image.open('./validation/dew/2264.jpg')
img2 = Image.open('./validation/frost/3676.jpg')

fig, axes = plt.subplots(1,  2, figsize=(12,  6))
axes[0].imshow(img1)
axes[0].axis('off')
axes[1].imshow(img2)
axes[1].axis('off')
plt.show()
```
![image](https://github.com/dev-aram/KDT_TASK/assets/135501045/983cd66a-8a11-4950-a190-4d8a466d7303)

> ìœ„ ì´ë¯¸ì§€ë¥¼ ê°€ì§€ê³  í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰

```python
img1_input = data_transforms['validation'](img1)
img2_input = data_transforms['validation'](img2)
print(img1_input.shape)
print(img2_input.shape)

test_batch = torch.stack([img1_input, img2_input])
test_batch = test_batch.to(device)
test_batch.shape
y_pred = model(test_batch)
y_pred
```

```python
# ê°•ì‚¬ë‹˜ ì½”ë“œ
y_prob = nn.Softmax(1)(y_pred)
probs, idx = torch.topk(y_prob, k=3)

fig, axes = plt.subplots(1, 2, figsize=(15, 6))
axes[0].set_title('{:.2f}% {}, {:.2f}% {}, {:.2f}% {}'.format(
    probs[0, 0] * 100,
    image_datasets['validation'].classes[idx[0, 0]],
    probs[0, 1] * 100,
    image_datasets['validation'].classes[idx[0, 1]],
    probs[0, 2] * 100,
    image_datasets['validation'].classes[idx[0, 2]],
))
axes[0].imshow(img1)
axes[0].axis('off')
axes[1].set_title('{:.2f}% {}, {:.2f}% {}, {:.2f}% {}'.format(
    probs[1, 0] * 100,
    image_datasets['validation'].classes[idx[1, 0]],
    probs[1, 1] * 100,
    image_datasets['validation'].classes[idx[1, 1]],
    probs[1, 2] * 100,
    image_datasets['validation'].classes[idx[1, 2]],
))
axes[1].imshow(img2)
axes[1].axis('off')
plt.show()
```

![image](https://github.com/dev-aram/KDT_TASK/assets/135501045/d5a5dbf7-7a11-441f-9bd0-3044741d5770)

ìœ„ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë§ê²Œ ë‚˜ì˜¨ê²ƒì„ í™•ì¸.
